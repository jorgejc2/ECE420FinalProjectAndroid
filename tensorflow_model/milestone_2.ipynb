{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final milestone notebook is for processing the data using a NVIDIA GPU and then feeding the images to the CNN rather than using the processed data from the tablet. More specifically, the MFCC algorithm will be run in CUDA. Any other algorithm involved in the process such as filtering, downsampling, trimming, and image generation is done in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "from scipy import signal\n",
    "import build.pybind_modules.dsp_module as cu\n",
    "import build.pybind_modules.matrix_module as myMatrix\n",
    "from math import ceil, isnan\n",
    "from time import time\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "MODEL_NAME = 'audio_mnist'\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Parameters used on tablet \n",
    "VOICED_THRESHOLD = 20000000\n",
    "FRAME_SETBACK = 2\n",
    "FS = 48000\n",
    "DOWN_SAMPLED_FS = 8000\n",
    "NFFT = 256\n",
    "NOVERLAP = -1\n",
    "NFILT = 40\n",
    "NUM_CEPS = 13\n",
    "NN_DATA_COLS = 28\n",
    "NN_DATA_ROWS = 12\n",
    "PREEMPHASIS_B = 0.97\n",
    "PIXEL_WIDTH = 400\n",
    "PIXEL_HEIGHT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" helper functions used in sample processing before feed the samples to the CNN \"\"\"\n",
    "def soundDataToFloat(SD):\n",
    "    \"Converts integer representation back into librosa-friendly floats, given a numpy array SD\"\n",
    "    return np.array([ np.float32(s/32768.0) for s in SD])\n",
    "\n",
    "def soundDataToInt16(SD):\n",
    "    return np.array( [np.int16(s*32768.0) for s in SD] )\n",
    "\n",
    "def createButter(N, Wn, fs):\n",
    "    num, den = signal.butter(N, Wn, btype='low', analog=False, output='ba', fs=fs)\n",
    "    return np.array([num[i]/den[i] for i in range(len(num))])\n",
    "\n",
    "def createFIR(num_taps, cut_off, fs):\n",
    "    return signal.firwin(num_taps, cut_off, fs=fs)\n",
    "\n",
    "def displayFIR(filt):\n",
    "    coef_str = \"{\" \n",
    "    for val in filt: \n",
    "        coef_str += str(val) + \", \" \n",
    "    coef_str = coef_str[:-2] \n",
    "    coef_str += \"};\" \n",
    "    print(\"FIR a Coefficients\")\n",
    "    print(coef_str) \n",
    "\n",
    "def applyFIR(samples, filt):\n",
    "    circBuf = np.zeros(len(filt))\n",
    "    circBufIdx = 0\n",
    "    filteredSamples = np.zeros(len(samples))\n",
    "    num_taps = len(filt)\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        circBuf[circBufIdx] = samples[i]\n",
    "        curr_val = 0\n",
    "\n",
    "        for n in range(num_taps):\n",
    "            curr_val += filt[n] * circBuf[ (((circBufIdx - n) % num_taps) + num_taps) % num_taps]\n",
    "\n",
    "        filteredSamples[i] = curr_val \n",
    "        circBufIdx = (circBufIdx + 1) % num_taps\n",
    "\n",
    "    return filteredSamples\n",
    "\n",
    "def frameVoiced(frame, threshold):\n",
    "    isVoiced = False\n",
    "    sum = 0\n",
    "    for i in range(len(frame)):\n",
    "        sum += abs(frame[i])**2\n",
    "\n",
    "    if (sum > threshold):\n",
    "        isVoiced = 1\n",
    "    \n",
    "    return isVoiced\n",
    "\n",
    "def trimSamples(samples, frameSize, nfft, noverlap, threshold, frame_setback):\n",
    "    num_samples = len(samples)\n",
    "    if (noverlap < 0):\n",
    "        noverlap = int(nfft/2)\n",
    "\n",
    "    step = nfft - noverlap\n",
    "\n",
    "    numFrames = ceil(num_samples / step)\n",
    "\n",
    "    while ((numFrames - 1)*step + (nfft - 1) >= num_samples):\n",
    "        numFrames -= 1\n",
    "\n",
    "    first_frame = 0\n",
    "    for i in range(numFrames):\n",
    "        if frameVoiced(soundDataToInt16(samples[i*step:i*step + nfft]), threshold=threshold):\n",
    "            first_frame = i\n",
    "            break\n",
    "    \n",
    "    first_frame -= frame_setback\n",
    "    if first_frame < 0:\n",
    "        first_frame = 0\n",
    "    last_frame = first_frame + frameSize\n",
    "    num_trimmed_samples = ((last_frame - 1)*step + nfft) - (first_frame*step)\n",
    "    trimmed_samples = np.zeros(num_trimmed_samples)\n",
    "\n",
    "    for i in range(num_trimmed_samples):\n",
    "        if (first_frame*step + i >= len(samples)):\n",
    "            break\n",
    "        trimmed_samples[i] = samples[first_frame*step + i]\n",
    "\n",
    "    return trimmed_samples\n",
    "\n",
    "def createImage(data, pixel_width, pixel_height, data_rows, data_cols, filename=None):\n",
    "    def hex_to_rgb(val):\n",
    "        mask = 0x0000FF\n",
    "        b = mask & val\n",
    "        g = mask & (val >> 8)\n",
    "        r = mask & (val >> 16)\n",
    "        \n",
    "        return (r,g,b)\n",
    "\n",
    "    viridis_pallete = [\n",
    "        0x440154,\n",
    "        0x481567,\n",
    "        0x482677,\n",
    "        0x453771,\n",
    "        0x404788,\n",
    "        0x39568C,\n",
    "        0x33638D,\n",
    "        0x2D708E,\n",
    "        0x287D8E,\n",
    "        0x238A8D,\n",
    "        0x1F968B,\n",
    "        0x20A387,\n",
    "        0x29AF7F,\n",
    "        0x3CBB75,\n",
    "        0x55C667,\n",
    "        0x73D055,\n",
    "        0x95D840,\n",
    "        0xB8DE29,\n",
    "        0xDCE319,\n",
    "        0xFDE725\n",
    "    ]\n",
    "    viridis_pallete_rgb = [hex_to_rgb(x) for x in viridis_pallete]\n",
    "    viridis_size = len(viridis_pallete_rgb)\n",
    "\n",
    "    max_val = None\n",
    "    min_val = None\n",
    "    for y in range(data_rows):\n",
    "        for x in range(data_cols):\n",
    "            sample = data[y,x]\n",
    "            if isnan(sample):\n",
    "                sample = 0\n",
    "                data[y,x] = sample\n",
    "            if max_val == None or sample > max_val:\n",
    "                max_val = sample\n",
    "            if min_val == None or sample < min_val:\n",
    "                min_val = sample\n",
    "\n",
    "    max_val -= min_val\n",
    "    data = (data-min_val) / max_val\n",
    "\n",
    "    \"\"\" canvas for holding rgb image from the range 0 to 255 \"\"\"\n",
    "    canvas = np.zeros((pixel_height, pixel_width, 3), dtype=np.uint8)\n",
    "    horizontal_step = int(pixel_width / data_cols)\n",
    "    vertical_step = int(pixel_height / data_rows)\n",
    "\n",
    "    # attempting to only manipulate green in rgb\n",
    "\n",
    "    # step counters that are 1 indexed\n",
    "    horizontal_count = 1\n",
    "    vertical_count = 1\n",
    "    for pixel_row in range(pixel_height):\n",
    "        if (pixel_row >= vertical_count * vertical_step) and (vertical_count < data_rows):\n",
    "            vertical_count += 1\n",
    "\n",
    "        horizontal_count = 1\n",
    "        for pixel_col in range(pixel_width):\n",
    "            if (pixel_col >= horizontal_count * horizontal_step) and (horizontal_count < data_cols):\n",
    "                horizontal_count += 1\n",
    "            \n",
    "            # 0 index\n",
    "            x_idx = horizontal_count - 1\n",
    "            y_idx = data_rows - vertical_count\n",
    "\n",
    "            # determine green value from data\n",
    "            percent = data[y_idx, x_idx]\n",
    "\n",
    "            viridis_idx = int((viridis_size-1) * percent)\n",
    "            curr_color = viridis_pallete_rgb[viridis_idx]\n",
    "\n",
    "            red_val = curr_color[0]\n",
    "            green_val = curr_color[1]\n",
    "            blue_val = curr_color[2]\n",
    "            \n",
    "            canvas[pixel_row, pixel_col, 0] = red_val\n",
    "            canvas[pixel_row, pixel_col, 1] = green_val\n",
    "            canvas[pixel_row, pixel_col, 2] = blue_val\n",
    "\n",
    "    im = Image.fromarray(canvas)\n",
    "    if filename is not None:\n",
    "        im.save(filename) # if you wanted to save the image\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a filter\n",
    "filt = createFIR(51, 3500, fs=FS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jorge's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time: 2220.151901245117 ms\n",
      "GPU took on average 2176.17045266061 ms to process each file for 601 files\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + \"/MFCC_Images\"\n",
    "write_path = os.getcwd() + \"/MFCC_Images\"\n",
    "labeled_directories = os.listdir(path)\n",
    "total_processes = 1\n",
    "total_time = 0\n",
    "print_once = 1\n",
    "for i in range(len(labeled_directories)):\n",
    "    label = labeled_directories[i]\n",
    "    curr_label = int(label)\n",
    "    # print(curr_label)\n",
    "\n",
    "    image_directory_path = f\"{path}/{label}/raw_wav_audio\"\n",
    "    write_directory_path = f\"{write_path}/{label}/gpu_images\"\n",
    "    raw_wav_directory = os.listdir(image_directory_path)\n",
    "\n",
    "    if not os.path.exists(write_directory_path):\n",
    "        os.makedirs(write_directory_path)\n",
    "    \n",
    "    for j in range(len(raw_wav_directory)):\n",
    "        curr_raw_wav = raw_wav_directory[j]\n",
    "        curr_raw_wav_path = f\"{image_directory_path}/{curr_raw_wav}\"\n",
    "        raw_fs, raw_wav_audio = wavfile.read(curr_raw_wav_path)\n",
    "\n",
    "        start_process_time = time()\n",
    "\n",
    "        sig = soundDataToFloat(raw_wav_audio)\n",
    "\n",
    "        filtered_sig = applyFIR(sig, filt)\n",
    "\n",
    "        filtered_sig = np.array([filtered_sig[i] for i in range(0, len(filtered_sig), 6)])\n",
    "\n",
    "        filtered_sig = trimSamples(filtered_sig, NN_DATA_COLS, NFFT, NOVERLAP, VOICED_THRESHOLD, FRAME_SETBACK)\n",
    "\n",
    "        curr_processed = np.array(myMatrix.MFCC_Matrix(list(filtered_sig), DOWN_SAMPLED_FS, NFFT, NOVERLAP, 2, PREEMPHASIS_B, NFILT, NUM_CEPS), copy=False)[1:,:]\n",
    "\n",
    "        end_process_time = (time() - start_process_time)*1000 # record how long the process took in ms\n",
    "\n",
    "        write_wav_file_name = f\"{write_directory_path}/{curr_label}_{j}_gpu_image.png\"\n",
    "\n",
    "        createImage(curr_processed, PIXEL_WIDTH, PIXEL_HEIGHT, NN_DATA_ROWS, NN_DATA_COLS, filename=write_wav_file_name)\n",
    "\n",
    "        if print_once:\n",
    "            print_once = 0\n",
    "            print(\"First time: {} ms\".format(end_process_time))\n",
    "\n",
    "        total_time += end_process_time\n",
    "        total_processes += 1\n",
    "\n",
    "total_processes -= 1\n",
    "Average_Process_Time = total_time / total_processes\n",
    "\n",
    "print(\"GPU took on average {} ms to process each file for {} files\".format(Average_Process_Time, total_processes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jonathan's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time: 2253.852605819702 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4974/3156656997.py:22: WavFileWarning: Reached EOF prematurely; finished at 196608 bytes, expected 288044 bytes from header.\n",
      "  raw_fs, raw_wav_audio = wavfile.read(curr_raw_wav_path)\n",
      "/tmp/ipykernel_4974/3156656997.py:22: WavFileWarning: Reached EOF prematurely; finished at 262144 bytes, expected 288044 bytes from header.\n",
      "  raw_fs, raw_wav_audio = wavfile.read(curr_raw_wav_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU took on average 2186.432551404197 ms to process each file for 613 files\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + \"/Jonathan_MFCC_Images\"\n",
    "write_path = os.getcwd() + \"/Jonathan_MFCC_Images\"\n",
    "labeled_directories = os.listdir(path)\n",
    "total_processes = 1\n",
    "total_time = 0\n",
    "print_once = 1\n",
    "for i in range(len(labeled_directories)):\n",
    "    label = labeled_directories[i]\n",
    "    curr_label = int(label)\n",
    "    # print(curr_label)\n",
    "\n",
    "    image_directory_path = f\"{path}/{label}/raw_wav_audio\"\n",
    "    write_directory_path = f\"{write_path}/{label}/gpu_images\"\n",
    "    raw_wav_directory = os.listdir(image_directory_path)\n",
    "\n",
    "    if not os.path.exists(write_directory_path):\n",
    "        os.makedirs(write_directory_path)\n",
    "    \n",
    "    for j in range(len(raw_wav_directory)):\n",
    "        curr_raw_wav = raw_wav_directory[j]\n",
    "        curr_raw_wav_path = f\"{image_directory_path}/{curr_raw_wav}\"\n",
    "        raw_fs, raw_wav_audio = wavfile.read(curr_raw_wav_path)\n",
    "\n",
    "        start_process_time = time()\n",
    "\n",
    "        sig = soundDataToFloat(raw_wav_audio)\n",
    "\n",
    "        filtered_sig = applyFIR(sig, filt)\n",
    "\n",
    "        filtered_sig = np.array([filtered_sig[i] for i in range(0, len(filtered_sig), 6)])\n",
    "\n",
    "        filtered_sig = trimSamples(filtered_sig, NN_DATA_COLS, NFFT, NOVERLAP, VOICED_THRESHOLD, FRAME_SETBACK)\n",
    "\n",
    "        curr_processed = np.array(myMatrix.MFCC_Matrix(list(filtered_sig), DOWN_SAMPLED_FS, NFFT, NOVERLAP, 2, PREEMPHASIS_B, NFILT, NUM_CEPS), copy=False)[1:,:]\n",
    "\n",
    "        end_process_time = (time() - start_process_time)*1000 # record how long the process took in ms\n",
    "\n",
    "        write_wav_file_name = f\"{write_directory_path}/{curr_label}_{j}_gpu_image.png\"\n",
    "\n",
    "        createImage(curr_processed, PIXEL_WIDTH, PIXEL_HEIGHT, NN_DATA_ROWS, NN_DATA_COLS, filename=write_wav_file_name)\n",
    "\n",
    "        if print_once:\n",
    "            print_once = 0\n",
    "            print(\"First time: {} ms\".format(end_process_time))\n",
    "\n",
    "        total_time += end_process_time\n",
    "        total_processes += 1\n",
    "\n",
    "total_processes -= 1\n",
    "Average_Process_Time = total_time / total_processes\n",
    "\n",
    "print(\"GPU took on average {} ms to process each file for {} files\".format(Average_Process_Time, total_processes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time: 2274.200439453125 ms\n",
      "GPU took on average 2193.07440381995 ms to process each file for 434 files\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + \"/Max_MFCC_Images\"\n",
    "write_path = os.getcwd() + \"/Max_MFCC_Images\"\n",
    "labeled_directories = os.listdir(path)\n",
    "total_processes = 1\n",
    "total_time = 0\n",
    "print_once = 1\n",
    "for i in range(len(labeled_directories)):\n",
    "    label = labeled_directories[i]\n",
    "    curr_label = int(label)\n",
    "    # print(curr_label)\n",
    "\n",
    "    image_directory_path = f\"{path}/{label}/raw_wav_audio\"\n",
    "    write_directory_path = f\"{write_path}/{label}/gpu_images\"\n",
    "    raw_wav_directory = os.listdir(image_directory_path)\n",
    "\n",
    "    if not os.path.exists(write_directory_path):\n",
    "        os.makedirs(write_directory_path)\n",
    "    \n",
    "    for j in range(len(raw_wav_directory)):\n",
    "        curr_raw_wav = raw_wav_directory[j]\n",
    "        curr_raw_wav_path = f\"{image_directory_path}/{curr_raw_wav}\"\n",
    "        raw_fs, raw_wav_audio = wavfile.read(curr_raw_wav_path)\n",
    "\n",
    "        start_process_time = time()\n",
    "\n",
    "        sig = soundDataToFloat(raw_wav_audio)\n",
    "\n",
    "        filtered_sig = applyFIR(sig, filt)\n",
    "\n",
    "        filtered_sig = np.array([filtered_sig[i] for i in range(0, len(filtered_sig), 6)])\n",
    "\n",
    "        filtered_sig = trimSamples(filtered_sig, NN_DATA_COLS, NFFT, NOVERLAP, VOICED_THRESHOLD, FRAME_SETBACK)\n",
    "\n",
    "        curr_processed = np.array(myMatrix.MFCC_Matrix(list(filtered_sig), DOWN_SAMPLED_FS, NFFT, NOVERLAP, 2, PREEMPHASIS_B, NFILT, NUM_CEPS), copy=False)[1:,:]\n",
    "\n",
    "        end_process_time = (time() - start_process_time)*1000 # record how long the process took in ms\n",
    "\n",
    "        write_wav_file_name = f\"{write_directory_path}/{curr_label}_{j}_gpu_image.png\"\n",
    "\n",
    "        createImage(curr_processed, PIXEL_WIDTH, PIXEL_HEIGHT, NN_DATA_ROWS, NN_DATA_COLS, filename=write_wav_file_name)\n",
    "\n",
    "        if print_once:\n",
    "            print_once = 0\n",
    "            print(\"First time: {} ms\".format(end_process_time))\n",
    "\n",
    "        total_time += end_process_time\n",
    "        total_processes += 1\n",
    "\n",
    "total_processes -= 1\n",
    "Average_Process_Time = total_time / total_processes\n",
    "\n",
    "print(\"GPU took on average {} ms to process each file for {} files\".format(Average_Process_Time, total_processes))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
